{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RBIntel_Create.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0hHCW-qPMeH6",
        "g-eNzM614b3K",
        "QUSiy6rYZOi0",
        "PWjbHbRSL3Mp",
        "k-BLJbiwWTQ1",
        "LhI6k0c6O3_h"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPcmao2bwSBCPv0AxQ2vYS8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BNIA/VitalSigns/blob/main/RBIntel_Create.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfS6dG17ZEaz"
      },
      "source": [
        "# Welcome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jLE_5-I9HzS"
      },
      "source": [
        "# Housing -> RBIntel -> Data Intake and Operations\n",
        "\n",
        "> This notebook uses data to generate a portion of BNIA's Vital Signs report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSNOAJoTlQr0"
      },
      "source": [
        "This colab and more can be found at https://github.com/BNIA/colabs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukxt0JZCsaxc"
      },
      "source": [
        "## Whats Inside?: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo5GYquJovv-"
      },
      "source": [
        "#### __Indicators Used__\n",
        "\n",
        "- ✅ 30 - __dom__ - (RBIntel) Median Number of Days on the Market\n",
        "- ✅ 38 - __cashsa__ - (RBIntel) Percentage of residential sales for cash\n",
        "- ✅ 39 - __reosa__ - (RBIntel) percentage of residential sales in foreclosure (REO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNveDD1Ho0mY"
      },
      "source": [
        "#### __Datasets Used__\n",
        "\n",
        "- ✔️ housing.rbintelregion_201X __(30-dom, 38-cashsa, 39-reosa -> DaysOnMark, newtrust1l, foreclosur)__\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK4HOnSWrpy-"
      },
      "source": [
        "#### __Operations Performed__\n",
        "\n",
        "- Reading in data (points/ geoms)\n",
        "-- Convert lat/lng columns to point coordinates\n",
        "-- Geocoding address to coordinates\n",
        "-- Changing coordinate reference systems\n",
        "- Basic Operations\n",
        "- Saving shape data\n",
        "- Get Polygon Centroids\n",
        "- Working with Points and Polygons\n",
        "-- Map Points and Polygons\n",
        "-- Get Points in Polygons\n",
        "-- Create Choropleths\n",
        "-- Create Heatmaps (KDE?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8-mgsByhrxG"
      },
      "source": [
        "## SETUP Enviornment:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hHCW-qPMeH6"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUvcamATFo4G"
      },
      "source": [
        "%%capture\n",
        "! pip install -U -q PyDrive\n",
        "! pip install geopy\n",
        "! pip install geopandas\n",
        "! pip install geoplot\n",
        "! pip install dataplay\n",
        "! pip install matplotlib\n",
        "! pip install psycopg2-binary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0vkoXtZRdJz"
      },
      "source": [
        "%%capture\n",
        "! apt-get install build-dep python-psycopg2\n",
        "! apt-get install libpq-dev\n",
        "! apt-get install libspatialindex-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ17xjOgR8vg"
      },
      "source": [
        "%%capture\n",
        "!pip install rtree\n",
        "!pip install dexplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Mcvm-X0gdo"
      },
      "source": [
        "from dataplay.geoms import workWithGeometryData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNOByHFKFo4m"
      },
      "source": [
        "%%capture \n",
        "# These imports will handle everything\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from geopandas import GeoDataFrame\n",
        "import psycopg2\n",
        "import pyproj\n",
        "from pyproj import Proj, transform\n",
        "# conda install -c conda-forge proj4\n",
        "from shapely.geometry import Point\n",
        "from shapely import wkb\n",
        "from shapely.wkt import loads\n",
        "# https://pypi.org/project/geopy/\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "# In case file is KML, enable support\n",
        "import fiona\n",
        "fiona.drvsupport.supported_drivers['kml'] = 'rw'\n",
        "fiona.drvsupport.supported_drivers['KML'] = 'rw'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evj9GJLdSlxF"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTcb3bD84mSA"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8tLzJzcMh74"
      },
      "source": [
        "### Configure Enviornment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuH4mBeYCUqU"
      },
      "source": [
        "# This will just beautify the output\n",
        "\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('display.precision', 2)\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "# pd.set_option('display.expand_frame_repr', False)\n",
        "# pd.set_option('display.precision', 2)\n",
        "# pd.reset_option('max_colwidth')\n",
        "pd.set_option('max_colwidth', 20)\n",
        "# pd.reset_option('max_colwidth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eurOj6j3AiPe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-eNzM614b3K"
      },
      "source": [
        "## Prep Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3QiG_W4iDl7"
      },
      "source": [
        "#### TPOP CSA and Baltimore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlQvkkbaB0ZI"
      },
      "source": [
        "Get Baltimore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xeV9WHdOhBv"
      },
      "source": [
        "#collapse_output\n",
        "#collapse_input\n",
        "csa = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Tpop/FeatureServer/0/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n",
        "csa = gpd.read_file(csa);\n",
        "csa.head(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyBS5PlHB1db"
      },
      "source": [
        "Get CSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FLpVhiPUAck"
      },
      "source": [
        "url2 = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Tpop/FeatureServer/1/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\"\n",
        "csa2 = gpd.read_file(url2);\n",
        "csa2['CSA2010'] = csa2['City_1'] \n",
        "csa2['OBJECTID'] = 56 \n",
        "csa2 = csa2.drop(columns=['City_1'])\n",
        "csa2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiT-Pc1jgZJI"
      },
      "source": [
        "Append do no append Bcity. We put it on the Bottom of the df because when performing the ponp it returns only the last matching columns CSA Label. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWZigszHUWm5"
      },
      "source": [
        "# csa = pd.concat([csa2, csa], ignore_index=True)\n",
        "csa = csa.append(csa2).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH6C5OecjBsy"
      },
      "source": [
        "csa.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLpXYhJHB_rt"
      },
      "source": [
        "csa.tail(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpZDcRVkk9SJ"
      },
      "source": [
        "csa.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG_g3sp2J2pq"
      },
      "source": [
        "csa.drop(columns=['Shape__Area', 'Shape__Length', 'OBJECTID'], axis=1).to_file(\"BCity_and_CSA.geojson\", driver='GeoJSON')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-cCU7os4zus"
      },
      "source": [
        "### Mdprop -  [totalres](https://bniajfi.org/indicators/Housing%20And%20Community%20Development/totalres)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adWpvpT4vyWl"
      },
      "source": [
        "https://dev.bniajfi.org/indicators/Housing%20And%20Community%20Development/ownroc/2018\n",
        "\n",
        "Baltimore City - 54.6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44L9YWWH65p0"
      },
      "source": [
        "# total residential properties -> [totalres](https://bniajfi.org/indicators/Housing%20And%20Community%20Development/totalres)\n",
        "\n",
        "totalres = \"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Totalres/FeatureServer/0/query?where=1%3D1&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=totalres18%2C+CSA2010&returnGeometry=true&returnCentroid=false&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=\"\n",
        "\n",
        "totalres = gpd.read_file(totalres); # Has ACS 17 Queries, including tpop17 (we want tpop10).\n",
        "totalres.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUSiy6rYZOi0"
      },
      "source": [
        "## Points In Polygon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBlO9_s198_g"
      },
      "source": [
        "def retrieveAndcleanRbIntel(filename, year):\n",
        "  rbintel = gpd.read_file(filename);\n",
        "  print(len(rbintel));\n",
        "  # Convert to EPSG:4326\n",
        "  rbintel = rbintel.to_crs(epsg=4326)\n",
        "  rbintel.crs\n",
        "\n",
        "  rbintel['x'] = rbintel.geometry.x\n",
        "  rbintel['y'] = rbintel.geometry.y\n",
        "\n",
        "  # Reference: All Points\n",
        "  base = csa.plot(color='white', edgecolor='black')\n",
        "  rbintel.plot(ax=base, marker='o', color='green', markersize=5);\n",
        "\n",
        "  # Get CSA Labels for all Points.\n",
        "  rbintelCSA = workWithGeometryData( \n",
        "      method='ponp', df=rbintel, polys=csa, ptsCoordCol='geometry', \n",
        "      polygonsCoordCol='geometry', polyColorCol=False, polygonsLabel='CSA2010'\n",
        "  )\n",
        "  rbintelCSA = rbintelCSA.drop('geometry',axis=1)\n",
        "  rbintelCSA.to_csv('ponp_rbintel_'+year+'.csv', index=False)\n",
        "  return rbintelCSA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSTod2szZB1j"
      },
      "source": [
        "rbintel17 = retrieveAndcleanRbIntel(\"RBIntelRegion_2017.shp\", '17');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIuv6iP0e3-c"
      },
      "source": [
        "rbintel18 = retrieveAndcleanRbIntel(\"RBIntelRegion_2018.shp\", '18');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObwTAlxAAp55"
      },
      "source": [
        "rbintel19 = retrieveAndcleanRbIntel(\"RBIntel_2019_BaltRegion.shp\", '19');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFatYduhLVFN"
      },
      "source": [
        "rbintel20 = retrieveAndcleanRbIntel(\"RBIntel_2020_BaltRegion.shp\", '20');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJnN5wBbeudH"
      },
      "source": [
        "Region17 and Region 18 should have a similar number of records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWjbHbRSL3Mp"
      },
      "source": [
        "## Preliminary Analysis W/ PonP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZPNxZPsngBR"
      },
      "source": [
        "import pandas as pd\n",
        "import geopandas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "r17 = pd.read_csv(\"ponp_rbintel_17.csv\");\n",
        "r18 = pd.read_csv(\"ponp_rbintel_18.csv\");\n",
        "r19 = pd.read_csv(\"ponp_rbintel_19.csv\");\n",
        "r17 = geopandas.GeoDataFrame( r17, geometry=geopandas.points_from_xy(r17.x, r17.y)) \n",
        "r18 = geopandas.GeoDataFrame( r18, geometry=geopandas.points_from_xy(r18.x, r18.y)) \n",
        "r19 = geopandas.GeoDataFrame( r19, geometry=geopandas.points_from_xy(r19.x, r19.y)) \n",
        "r19.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIq5lwPBhI20"
      },
      "source": [
        "cd ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig0qFxGmFtt-"
      },
      "source": [
        "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html\n",
        "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html\n",
        "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html\n",
        "# https://stackoverflow.com/questions/41308763/python-pandas-df-duplicated-and-df-drop-duplicated-not-finding-all-duplicates\n",
        "def exploreDs(df, yr):\n",
        "\n",
        "  def createIndicatorAndPlotChoropleth(ddf, txt1):\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    csa.merge( vsDom(df, 'DOM_'+txt1+yr) , left_on='CSA2010', right_on='CSA2010' ).plot(column='dom', ax=ax, legend=True); plt.savefig('./output/img/DOM_Map_Of_the_'+txt1+yr+'.jpg')\n",
        "    csa.merge( vsCashsa(df, 'Cashsa_'+txt1+yr) , left_on='CSA2010', right_on='CSA2010' ).plot(column='cashsa', ax=ax, legend=True); plt.savefig('./output/img/Cashsa_Map_Of_the_'+txt1+yr+'.jpg')\n",
        "    csa.merge( vsReosa(df, 'Reosa_'+txt1+yr) , left_on='CSA2010', right_on='CSA2010' ).plot(column='reosa', ax=ax, legend=True); plt.savefig('./output/img/Reosa_Map_Of_the_'+txt1+yr+'.jpg')\n",
        "\n",
        "  def plotAndSave(ddf, txt):\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    base = csa.plot(color='white', edgecolor='black')\n",
        "    ddf.plot(ax=base, marker='o', color='green', markersize=5);\n",
        "    plt.savefig('./output/'+txt)\n",
        "\n",
        "  print('!~~~~~~~~~~~~~~~~~~~~~!STARTING!!!!!! ',yr,' !~~~~~~~~~~~~~~~~~~~~~!')\n",
        "\n",
        "  #\n",
        "  # Drop All un-needed Columns\n",
        "  df = df[['CSA2010', 'AddressLin', 'geometry', 'DaysOnMark', 'NewTrust1L', 'Foreclosur', 'SoldDate']]\n",
        "  # Sort the Dataset by Address\n",
        "  #\n",
        "  df = df.sort_values(by=['AddressLin']).reset_index()\n",
        "  print('Given: ', len(df), ' Records')\n",
        "  # Run this Indicators\n",
        "  createIndicatorAndPlotChoropleth(df, 'Untouched_Records')\n",
        "  # Plot it on a CSA Map\n",
        "  plotAndSave(df, 'Dot_Map_Of_the_Untouched_Records_'+yr+'.jpg') \n",
        "\n",
        "  #\n",
        "  # Drop the NON CSA Records\n",
        "  # Save a copy of the Dropped Records? \n",
        "  # - Nah. They wont effect our calculations and removing them adds clarity.\n",
        "  #\n",
        "  df.drop(df[df['CSA2010'] == 'false'].index, inplace=True)\n",
        "  print('There are ', len(df), ' Records Remaining after Droping Non-CSA Records')\n",
        "  # Run this Indicators\n",
        "  createIndicatorAndPlotChoropleth(df, 'Dropped_Non_CSA_Records')\n",
        "  # Plot it on a CSA Map\n",
        "  plotAndSave(df, 'Dot_Map_Of_the_Dropped_Non_CSA_Records_'+yr+'.jpg') \n",
        "\n",
        "  #\n",
        "  # Determines which duplicates (if any) to keep. \n",
        "  # - first : Drop duplicates except for the first occurrence. \n",
        "  # - last : Drop duplicates except for the last occurrence. \n",
        "  # - False : Drop all duplicates.\n",
        "  # Filter the dataset for duplicates in the AddressLin.\n",
        "  #\n",
        "  val1 = df.drop_duplicates(subset=['SoldDate', 'AddressLin'], keep='last').reset_index()\n",
        "  print('There are', len(val1) , ' Records Remaining after Droping all but the last Duplicate on SoldDate & AddressLin')\n",
        "  # Run this Indicators\n",
        "  createIndicatorAndPlotChoropleth(val1, 'Dropped_Non_CSA_Records_and_Deduped')\n",
        "  # Plot it on a CSA Map\n",
        "  plotAndSave(val1, 'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped_'+yr+'.jpg') \n",
        "  \n",
        "  #\n",
        "  # Save a copy of the data that was filtered out in a new dataset\n",
        "  #\n",
        "  val2 = df[df.duplicated(subset=['SoldDate', 'AddressLin'], keep=False)].reset_index()\n",
        "  print('Having Removed This Many: ', len(val2))\n",
        "  # Run this Indicators\n",
        "  createIndicatorAndPlotChoropleth(val2, 'Dropped_Non_CSA_Records_and_Kept_Only_Duplicates')\n",
        "  # Plot it on a CSA Map\n",
        "  plotAndSave(val2, 'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates_'+yr+'.jpg') \n",
        "\n",
        "  return ( val1, val2, df )\n",
        "\n",
        "r177, val217, val317 = exploreDs(r17, '17')\n",
        "r188, val218, val318 = exploreDs(r18, '18')\n",
        "r189, val219, val319 = exploreDs(r19, '19')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcBeu8UqUtWh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-BLJbiwWTQ1"
      },
      "source": [
        "## VS Indicator Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Sl2C2fe6P_p"
      },
      "source": [
        "# I want to see how many points are in each polygon.\n",
        "\n",
        "# https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/dom/FeatureServer/layers\n",
        "# https://bniajfi.org/indicators/Housing%20And%20Community%20Development/dom\n",
        "\n",
        "def vsDom(df, yr):\n",
        "  print( 'Unique Foreclosure Values', df.Foreclosur.unique() )\n",
        "  print( 'Unique NewTrust1L  Values', df.NewTrust1L.unique() )\n",
        "\n",
        "  dom = df[['DaysOnMark','CSA2010']].copy()\n",
        "  dom['ponpcount'+yr] = 1\n",
        "  domDenominator = dom.copy()\n",
        "  dom = domDenominator.groupby('CSA2010').median(numeric_only=True) # use .median to calculate DOM.\n",
        "  dom['ponpcount'+yr] = domDenominator.groupby('CSA2010').sum(numeric_only=True)['ponpcount'+yr] # use .median to calculate DOM.\n",
        "  dom['dom'] = dom['DaysOnMark']\n",
        "  dom = dom.reset_index()\n",
        "  dom = dom[['dom', 'ponpcount'+yr, 'CSA2010']]\n",
        "  # Next steps create Baltimore's record\n",
        "  # Remove the 'False' Records\n",
        "  reapp = dom.loc[len(dom)-1]\n",
        "  dom = dom.drop([len(dom)-1])\n",
        "  # Create Baltimore\n",
        "  dom = dom.append({'CSA2010': 'Baltimore City' , 'ponpcount'+yr:  dom['ponpcount'+yr].sum()/55, 'dom' : dom['dom'].sum()/55 } , ignore_index=True)\n",
        "  # Reappend the False records\n",
        "  dom = dom.append(reapp)\n",
        "  dom.to_csv('./output/'+yr+'.csv', index=False)\n",
        "  return dom\n",
        "\"\"\"\n",
        "print('~~~~~~~~~~18~~~~~~~~~~~~~~~~~')\n",
        "vsDom(r18, '18').tail()\n",
        "print('~~~~~~~~~~~17~~~~~~~~~~~~~~~~')\n",
        "vsDom(r17, '17').tail()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwL_4Ib_RFB3"
      },
      "source": [
        "def inspectCashaDenominator(df):\n",
        "  df.head()\n",
        "inspectCashaDenominator(r18)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0UgdSRY7ecQ"
      },
      "source": [
        "# I want to see how many points are in each polygon.\n",
        "\n",
        "# https://services1.arcgis.com/mVFRs7NF4iFitgbY/arcgis/rest/services/dom/FeatureServer/layers\n",
        "# https://bniajfi.org/indicators/Housing%20And%20Community%20Development/dom\n",
        "\n",
        "def vsCashsa(df, yr):\n",
        "  print( 'Unique Foreclosure Values', df.Foreclosur.unique() )\n",
        "  print( 'Unique NewTrust1L  Values', df.NewTrust1L.unique() )\n",
        "\n",
        "  # Denominator\n",
        "  cashsa = df[['NewTrust1L','CSA2010']].copy()\n",
        "  cashsa['ponpcount'+yr] = 1\n",
        "  cashsaDenominator = cashsa.copy()\n",
        "  # Sum using ALL in CSA\n",
        "  cashsaDenominator = cashsa.groupby('CSA2010').sum(numeric_only=True) \n",
        "  # cashsa = cashsa.reset_index()\n",
        "  # cashsa = cashsa[['cashsa', 'ponpcount', 'CSA2010']]\n",
        "\n",
        "  # Filter to get applicable records for the Numerator\n",
        "  cashsa = cashsa[ cashsa['NewTrust1L'].str.contains('.Cash.|.Cash|Cash.|Cash', regex=True, na=False) ]\n",
        "  # Save the filtered list\n",
        "  cashsa.to_csv('./output/'+'cashsa_Filtered_Records'+yr+'.csv', index=False)\n",
        "  print(\"LENGTH: \", len(cashsa) )\n",
        "  # Now Sum the filtered list by csa to get our Numerator value\n",
        "  cashsa = cashsa.groupby('CSA2010').sum(numeric_only=True) \n",
        "  # Create the Indicator\n",
        "  cashsa['cashsa'] = cashsa['ponpcount'+yr] * 100 / cashsaDenominator['ponpcount'+yr] \n",
        "  cashsa = cashsa.reset_index()\n",
        "  cashsa = cashsa[ ['CSA2010', 'ponpcount'+yr, 'cashsa' ] ]\n",
        "  # Create Baltimore's Record\n",
        "  # Remove the 'False' Records\n",
        "  reapp = cashsa.loc[len(cashsa)-1]\n",
        "  cashsa = cashsa.drop([len(cashsa)-1])\n",
        "  cashsa = cashsa.append({'CSA2010': 'Baltimore City' , \n",
        "                              'ponpcount'+yr:  cashsa['cashsa'].sum(), \n",
        "                              'cashsa' : cashsa['cashsa'].sum()/55 } , ignore_index=True)\n",
        "  # Reappend the False records\n",
        "  cashsa = cashsa.append(reapp)\n",
        "  cashsa.to_csv('./output/'+yr+'.csv', index=False)\n",
        "  return cashsa\n",
        "\"\"\"\n",
        "print('~~~~~~~~~~18~~~~~~~~~~~~~~~~~')\n",
        "vsCashsa(r18, '18').head()\n",
        "vsCashsa(r18, '18').tail()\n",
        "print('~~~~~~~~~~~17~~~~~~~~~~~~~~~~')\n",
        "vsCashsa(r17, '17').head()\n",
        "vsCashsa(r17, '17').tail()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhoIe2N9RSgY"
      },
      "source": [
        "def inspectReosaDenominator(df, yr):\n",
        "  print( 'Unique Foreclosure Values', df.Foreclosur.unique() )\n",
        "  print( 'Unique NewTrust1L  Values', df.NewTrust1L.unique() )\n",
        "  # Dedupe on 'AddressLin', 'SoldDate\n",
        "  print( \"Original Dataset's Length: \", len(df))\n",
        "  temp = r18.drop_duplicates(subset=['AddressLin', 'SoldDate'], keep='last')\n",
        "  print('Deduped Length: ', len(temp))\n",
        "  print('Numer of Records Removed: ', len(df) - len(temp))\n",
        "  # Drop any NA AddressLin\n",
        "  temp = temp.dropna(subset=['AddressLin'])\n",
        "  print('Num Removed With No NA Addresses: ', len(df) - len(temp))\n",
        "\n",
        "  temp.head(1) # CSA2010 AddressLin SoldDate\n",
        "  temp['count'] = 1\n",
        "  v1= temp.groupby(by=[\"CSA2010\",\"Foreclosur\"]).sum()\n",
        "  v2= temp.groupby(by=[\"CSA2010\",\"DaysOnMark\"]).median()\n",
        "  v3= temp.groupby(by=[\"CSA2010\",\"NewTrust1L\"]).sum() # .sort_values(by=['col1', 'col2'])\n",
        "  v1.to_csv('reosa_Deduped'+yr+'_CSAs_Unique_Foreclosure_Counts.csv', index=False)\n",
        "  v2.to_csv('reosa_Deduped'+yr+'_CSAs_Unique_DOM_Counts.csv', index=False) \n",
        "  v3.to_csv('reosa_Deduped'+yr+'_CSAs_Unique_CASHSA_Counts.csv', index=False) \n",
        "  return temp\n",
        "\n",
        "inspectReosaDenominator(r18, '18')  \n",
        "# Compare DS's for each CSA where Points Exists but A ForeClosure Value Does not."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1cXLPmtnVM7"
      },
      "source": [
        "# https://bniajfi.org/indicators/Housing%20And%20Community%20Development/reosa/2017\n",
        "def vsReosa(df, yr):\n",
        "  print( 'Unique Foreclosure Values', df.Foreclosur.unique() )\n",
        "  print( 'Unique NewTrust1L  Values', df.NewTrust1L.unique() )\n",
        "\n",
        "  # Get Denominator\n",
        "  reosa = df.copy()\n",
        "  resosa = reosa\n",
        "  reosa['reosaCount'+yr] = 1\n",
        "  reosaDenominator = reosa.copy() \n",
        "  reosaDenominator = reosaDenominator.groupby('CSA2010').sum(numeric_only=True) \n",
        "  # Filter to get applicable records for the Numerator\n",
        "  reosa = reosa[ reosa['Foreclosur'].str.contains('.Y.|.Y|Y.|Y', regex=True, na=False) ]\n",
        "  # Save the filtered list\n",
        "  reosa.to_csv('./output/'+'reosa_Filtered_Records.csv', index=False)\n",
        "  print(\"LENGTH: \", len(reosa) )\n",
        "  # Aggregate Numeric Values by Sum \n",
        "  # Now Sum the filtered list by csa to get our Numerator value\n",
        "  reosa = reosa.groupby('CSA2010').sum(numeric_only=True) \n",
        "\n",
        "   \n",
        "  # Create the Indicator\n",
        "  reosa['reosa'] = reosa['reosaCount'+yr] * 100 / reosaDenominator['reosaCount'+yr] \n",
        "  reosa = reosa.reset_index()\n",
        "  reosa = reosa[ ['CSA2010', 'reosaCount'+yr, 'reosa' ] ]\n",
        "  # Create Baltimore's Record\n",
        "  # Remove the 'False' Records \n",
        "  reapp = reosa.loc[len(reosa)-1]\n",
        "  reosa = reosa.drop([len(reosa)-1])\n",
        "  reosa = reosa.append({'CSA2010': 'Baltimore City' , \n",
        "                              'reosaCount'+yr:  reosa['reosa'].sum(), \n",
        "                              'reosa' : reosa['reosa'].sum()/(len(reosa)-1) } , ignore_index=True)\n",
        "  # Reappend the False records\n",
        "  reosa = reosa.append(reapp)\n",
        "  reosa.to_csv('./output/'+yr+'.csv', index=False)\n",
        "  return reosa\n",
        "\"\"\"\n",
        "print('~~~~~~~~~~18~~~~~~~~~~~~~~~~~')\n",
        "vsReosa(r18, '18').head()\n",
        "vsReosa(r18, '18').tail()\n",
        "print('~~~~~~~~~~~17~~~~~~~~~~~~~~~~')\n",
        "vsReosa(r17, '17').head()\n",
        "vsReosa(r17, '17').tail()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj9eGb-3C-IM"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeOdABI3aQ7U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhI6k0c6O3_h"
      },
      "source": [
        "# Review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx1GENHcO4uk"
      },
      "source": [
        "cd output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6SWTVKLRrAT"
      },
      "source": [
        "!pip install ipywidgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XxVR4z-SMNs"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF7n2O9zSiYK"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fbUkDRWTOf9"
      },
      "source": [
        "# imgs = os.listdir('./img')\n",
        "imgs = ! ls img/18_DOM*.jpg\n",
        "for ele in enumerate(imgs): \n",
        "    imgs[ ele[0] ] = ele[1][10:]\n",
        "imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRU_oWqhrpk-"
      },
      "source": [
        "# Untouched_Records    Dropped_Non_CSA_Records    Dropped_Non_CSA_Records_and_Deduped    Dropped_Non_CSA_Records_and_Kept_Only_Duplicates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7W95c472R7V"
      },
      "source": [
        "from google.colab import widgets\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from matplotlib import pylab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31atrCAFJa32"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1oQrE5m7LdG"
      },
      "source": [
        "#@title String fields\n",
        "\n",
        "text = 'value' #@param {type:\"string\"}\n",
        "ind = 'Reosa' #@param ['DOM', \"Cashsa\", \"Reosa\",\"Dot\"]\n",
        "inspect = 'Untouched_Records' #@param ['Dropped_Non_CSA_Records18', 'Dropped_Non_CSA_Records_and_Deduped', 'Dropped_Non_CSA_Records_and_Kept_Only_Duplicates', 'Untouched_Records'] {allow-input: true}\n",
        "\n",
        "grid = widgets.Grid(4, 2)  \n",
        "filename17 = ind+'_Map_Of_the_'+'Untouched_Records'+'17.jpg'\n",
        "filename18 = ind+'_Map_Of_the_'+'Untouched_Records'+'18.jpg'\n",
        "filename172 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records'+'17.jpg'\n",
        "filename182 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records'+'18.jpg'\n",
        "filename172 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records_and_Deduped'+'17.jpg'\n",
        "filename182 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records_and_Deduped'+'18.jpg'\n",
        "filename173 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records'+'17.jpg'\n",
        "filename183 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records'+'18.jpg'\n",
        "filename174 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records'+'17.jpg'\n",
        "filename184 = ind+'_Map_Of_the_'+'Dropped_Non_CSA_Records'+'18.jpg'\n",
        "with grid.output_to(0, 0):\n",
        "  print(filename17)\n",
        "  display(Image(filename17))\n",
        "with grid.output_to(0, 1):\n",
        "  print(filename18)\n",
        "  display(Image(filename18))\n",
        "with grid.output_to(1, 0):\n",
        "  print(filename172)\n",
        "  display(Image(filename172))\n",
        "with grid.output_to(1, 1): \n",
        "  print(filename182)\n",
        "  display(Image(filename182))\n",
        "with grid.output_to(2, 0):\n",
        "  print(filename173)\n",
        "  display(Image(filename173))\n",
        "with grid.output_to(2, 1): \n",
        "  print(filename183)\n",
        "  display(Image(filename183))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU4o2NGDanr1"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ2eUh_pefkG"
      },
      "source": [
        "show_images([mpimg.imread('Cashsa_Map_Of_the_Dropped_Non_CSA_Records17.jpg'),\n",
        "mpimg.imread('Cashsa_Map_Of_the_Dropped_Non_CSA_Records18.jpg'),\n",
        "mpimg.imread('Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped17.jpg'),\n",
        "mpimg.imread('Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped18.jpg'),\n",
        "mpimg.imread('Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates17.jpg'),\n",
        "mpimg.imread('Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates18.jpg'),\n",
        "mpimg.imread('Cashsa_Map_Of_the_Untouched_Records17.jpg'),\n",
        "mpimg.imread('Cashsa_Map_Of_the_Untouched_Records18.jpg')], \n",
        "cols = 4, saveimg='CashsaMapMatrix.jpg', \n",
        "titles = ['Cashsa_Map_Of_the_Dropped_Non_CSA_Records17.jpg',\n",
        "'Cashsa_Map_Of_the_Dropped_Non_CSA_Records18.jpg',\n",
        "'Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped17.jpg',\n",
        "'Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped18.jpg',\n",
        "'Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates17.jpg',\n",
        "'Cashsa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates18.jpg',\n",
        "'Cashsa_Map_Of_the_Untouched_Records17.jpg',\n",
        "'Cashsa_Map_Of_the_Untouched_Records18.jpg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwyQ8N3md8yI"
      },
      "source": [
        "show_images([mpimg.imread('DOM_Map_Of_the_Dropped_Non_CSA_Records17.jpg'),\n",
        "mpimg.imread('DOM_Map_Of_the_Dropped_Non_CSA_Records18.jpg'),\n",
        "mpimg.imread('DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped17.jpg'),\n",
        "mpimg.imread('DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped18.jpg'),\n",
        "mpimg.imread('DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates17.jpg'),\n",
        "mpimg.imread('DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates18.jpg'),\n",
        "mpimg.imread('DOM_Map_Of_the_Untouched_Records17.jpg'),\n",
        "mpimg.imread('DOM_Map_Of_the_Untouched_Records18.jpg')], \n",
        "cols = 4, saveimg='DOMMapMatrix.jpg', \n",
        "titles = ['DOM_Map_Of_the_Dropped_Non_CSA_Records17.jpg',\n",
        "'DOM_Map_Of_the_Dropped_Non_CSA_Records18.jpg',\n",
        "'DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped17.jpg',\n",
        "'DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped18.jpg',\n",
        "'DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates17.jpg',\n",
        "'DOM_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates18.jpg',\n",
        "'DOM_Map_Of_the_Untouched_Records17.jpg',\n",
        "'DOM_Map_Of_the_Untouched_Records18.jpg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRI6G8CEdFrm"
      },
      "source": [
        "show_images([mpimg.imread('Reosa_Map_Of_the_Dropped_Non_CSA_Records17.jpg'),\n",
        "mpimg.imread('Reosa_Map_Of_the_Dropped_Non_CSA_Records18.jpg'),\n",
        "mpimg.imread('Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped17.jpg'),\n",
        "mpimg.imread('Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped18.jpg'),\n",
        "mpimg.imread('Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates17.jpg'),\n",
        "mpimg.imread('Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates18.jpg'),\n",
        "mpimg.imread('Reosa_Map_Of_the_Untouched_Records17.jpg'),\n",
        "mpimg.imread('Reosa_Map_Of_the_Untouched_Records18.jpg')], \n",
        "cols = 4, saveimg='ReosaMapMatrix.jpg', \n",
        "titles = ['Reosa_Map_Of_the_Dropped_Non_CSA_Records17.jpg',\n",
        "'Reosa_Map_Of_the_Dropped_Non_CSA_Records18.jpg',\n",
        "'Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped17.jpg',\n",
        "'Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped18.jpg',\n",
        "'Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates17.jpg',\n",
        "'Reosa_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates18.jpg',\n",
        "'Reosa_Map_Of_the_Untouched_Records17.jpg',\n",
        "'Reosa_Map_Of_the_Untouched_Records18.jpg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK_-VOT_dFCy"
      },
      "source": [
        "show_images([mpimg.imread('Dot_Map_Of_the_Dropped_Non_CSA_Records_17.jpg'),\n",
        "mpimg.imread('Dot_Map_Of_the_Dropped_Non_CSA_Records_18.jpg'),\n",
        "mpimg.imread('Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped_17.jpg'),\n",
        "mpimg.imread('Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped_18.jpg'),\n",
        "mpimg.imread('Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates_17.jpg'),\n",
        "mpimg.imread('Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates_18.jpg'),\n",
        "mpimg.imread('Dot_Map_Of_the_Untouched_Records_17.jpg'),\n",
        "mpimg.imread('Dot_Map_Of_the_Untouched_Records_18.jpg')], \n",
        "cols = 4, saveimg='DotMapMatrix.jpg', \n",
        "titles = ['Dot_Map_Of_the_Dropped_Non_CSA_Records_17.jpg',\n",
        "'Dot_Map_Of_the_Dropped_Non_CSA_Records_18.jpg',\n",
        "'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped_17.jpg',\n",
        "'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped_18.jpg',\n",
        "'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates_17.jpg',\n",
        "'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates_18.jpg',\n",
        "'Dot_Map_Of_the_Untouched_Records_17.jpg',\n",
        "'Dot_Map_Of_the_Untouched_Records_18.jpg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98pLGOwQalTK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def show_images(images, cols = 1, titles = None, saveimg='test.jpg'):\n",
        "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
        "    \n",
        "    Parameters\n",
        "    ---------\n",
        "    images: List of np.arrays compatible with plt.imshow.\n",
        "    \n",
        "    cols (Default = 1): Number of columns in figure (number of rows is \n",
        "                        set to np.ceil(n_images/float(cols))).\n",
        "    \n",
        "    titles: List of titles corresponding to each image. Must have\n",
        "            the same length as titles.\n",
        "    \"\"\"\n",
        "    assert((titles is None)or (len(images) == len(titles)))\n",
        "    n_images = len(images)\n",
        "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
        "    fig = plt.figure()\n",
        "    for n, (image, title) in enumerate(zip(images, titles)):\n",
        "        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n",
        "        plt.imshow(image)\n",
        "        a.set_title(title)\n",
        "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
        "    plt.show()\n",
        "    fig.savefig(saveimg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDZyyMENS3RO"
      },
      "source": [
        "import matplotlib.image as mpimg \n",
        "f, axarr = plt.subplots(4,2)\n",
        "\n",
        "f1 = 'Dot_Map_Of_the_Dropped_Non_CSA_Records_17.jpg'\n",
        "f2 = 'Dot_Map_Of_the_Dropped_Non_CSA_Records_18.jpg'\n",
        "f3 = 'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped_17.jpg'\n",
        "f4 = 'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Deduped_18.jpg'\n",
        "f5 = 'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates_17.jpg'\n",
        "f6 = 'Dot_Map_Of_the_Dropped_Non_CSA_Records_and_Kept_Only_Duplicates_18.jpg'\n",
        "f7 = 'Dot_Map_Of_the_Untouched_Records_17.jpg'\n",
        "f8 = 'Dot_Map_Of_the_Untouched_Records_18.jpg'\n",
        "\n",
        "axarr[0,0].imshow(('test',mpimg.imread( f1 ) ) )\n",
        "axarr[1,0].imshow(mpimg.imread( f2 ) )\n",
        "axarr[2,0].imshow(mpimg.imread( f3 ) )\n",
        "axarr[3,0].imshow(mpimg.imread( f4 ) )\n",
        "axarr[0,1].imshow(mpimg.imread( f5 ) )\n",
        "axarr[1,1].imshow(mpimg.imread( f6 ) )\n",
        "axarr[2,1].imshow(mpimg.imread( f7 ) )\n",
        "axarr[3,1].imshow(mpimg.imread( f8 ) )\n",
        "f.set_size_inches(18.5, 10.5, forward=True)\n",
        "f.savefig('test.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnvmhyWsPO2f"
      },
      "source": [
        "grid = widgets.Grid(4, 2) \n",
        "with grid.output_to(0, 0):\n",
        "  print(f1)\n",
        "  display(Image(f1))\n",
        "with grid.output_to(0, 1):\n",
        "  print(f2)\n",
        "  display(Image(f2))\n",
        "with grid.output_to(1, 0):\n",
        "  print(f3)\n",
        "  display(Image(f3))\n",
        "with grid.output_to(1, 1):\n",
        "  print(f4)\n",
        "  display(Image(f4))\n",
        "with grid.output_to(2, 0):\n",
        "  print(f5)\n",
        "  display(Image(f5))\n",
        "with grid.output_to(2, 1):\n",
        "  print(f6)\n",
        "  display(Image(f6))\n",
        "with grid.output_to(3, 0):\n",
        "  print(f7)\n",
        "  display(Image(f7))\n",
        "with grid.output_to(3, 1):\n",
        "  print(f8)\n",
        "  display(Image(f8))\n",
        "grid.savefig('faces.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWhGy9FD7Ywm"
      },
      "source": [
        "imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N4EgjKJO81-"
      },
      "source": [
        "ls img/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfvsDCbsqPtc"
      },
      "source": [
        "df = pd.import_csv('_Map_Of_the_Untouched_Records');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUSZWyqiUy_F"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui5KiUAhp_9D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}